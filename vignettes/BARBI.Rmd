---
title: "BARBI Workflow"
author:
  name: Pratheepa Jeganathan
  affiliation: Department of Statistics, Stanford University
  email: jpratheepa31@gmail.com
package: BARBI
abstract: >
  BAyesian Reference analysis with Background Inteference (BARBI) provides a reliable statistical method to remove contaminating bacterial DNA from both high- and low-biomass samples.
output:
  BiocStyle::html_document:
    toc_float: true
vignette: >
    %\VignetteIndexEntry{BARBI Workflow}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
bibliography: BARBI.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Install [R](https://www.r-project.org/) and [RStudio](https://www.rstudio.com/). Open this `Rmd` `r Githubpkg("rstudio/rmarkdown")` file in RStudio. Then run the following code to install all required packages, including BARBI from Github repository.

```{r install_packages}
pkgs = c("DESeq2",
         "phyloseq",
         "dplyr",
         "tidyr",
         "R.utils",
         "BiocParallel",
          "doParallel",
         "parallel",
         "HDInterval",
         "grid",
         "xtable",
         "gtable",
         "gridExtra",
         "BiocStyle",
         "magrittr")

if (!requireNamespace("BiocManager")){
  install.packages("BiocManager")
}
   
BiocManager::install(setdiff(pkgs, installed.packages()))

devtools::install_github("PratheepaJ/BARBI")
```

Load packages:
```{r load_packages}
library(BARBI)
library(phyloseq)
library(DESeq2)
library(dplyr)
library(tidyr)
library(R.utils)
library(BiocParallel)
library(doParallel)
library(parallel)
library(HDInterval)
library(grid)
library(xtable)
library(gtable)
library(gridExtra)
library(BiocStyle)
library(magrittr)
```


# Example dataset 

We load an example dataset stored as a phyloseq object in the `BARBI` package (or use your own data stored as a phyloseq object)

##  Load the phyloseq object

- We first validate our method (BARBI) for removing contamination using a dilution series of eight known bacterial species in the standard ZymoBIOMICS microbial community (Zymo Research). 
- We saved this data as phyloseq object in the BARBI package.
- Seven rounds of six-fold dilutions from the standard, from 1:1 up to 1:279,936 ($n_{1} = 8$), as well as ten negative extraction controls $n_{2} = 10$,  were made. Then all $N =18$ specimens were processed and analyzed with the ZymoBIOMICSÂ® Service: Targeted Metagenomic Sequencing (Zymo Research, Irvine, CA), which leverages 16S rRNA gene sequencing. 


```{r read-phylo}
ps = ps
```

Specify that the samples are on the columns and taxa are on the rows of `otu_table`. 

```{r}
if(dim(otu_table(ps))[1]!=ntaxa(ps)){otu_table(ps) = t(otu_table(ps))}
```



## Adding blocks/batches

To reduce the batch-effects of contamination, we can specify the block information and analyze each block separately with BARBI.

We highly recommend that you keep track of batch effects (Especially DNA extraction and library prep batches), visualize your data with PCA on ranks or MDS, and separate your data into different blocks of necessary. 

In the example dataset, all samples are in one block.

```{r adding_blocks}
blocks = rep("Set1", nsamples(ps))

sample_data(ps)$block = blocks
```


## Remove taxa not in specimens (dilution series samples)

Identify the taxa that are not present in at least one dilution series sample and removed them from the phyloseq object. Label these species as contaminants. 

```{r filter_taxa}
ps = prune_taxa(taxa_sums(ps)>0, ps)
ps_specimen =  subset_samples(ps, SampleType %in% c("Standard"))
prevTaxaP = apply(otu_table(ps_specimen), 1, function(x){sum(x>0)})

Contaminants1 = names(prevTaxaP)[prevTaxaP == 0]
ps = prune_taxa(prevTaxaP > 0, ps)
ps
```

We identified 142 ASVs not is any dilution series samples, and they are classified as contaminants before using BARBI.

We use BARBI to infer true ASVs in each dilution series sample. 

## Library depth

We check the distribution of sample library depth to see whether there are samples with very small library depth that should be dropped from the analysis.

```{r filter-samples}
totalReads = colSums(otu_table(ps))
hist(log(totalReads), yaxs="i", xaxs="i", 
     main="Distribution of total reads per sample", 
     breaks=50)
```

We do not need to drop any sample. 


## Summary

We look at a summary of the specimens and negative control samples in each block. 

```{r summary_stat}
table(sample_data(ps)$SampleType,sample_data(ps)$block)
```

# BARBI 

## Prepare the phyloseq object for the BARBI method

We use BARBI to identify contaminants in each block separately. 
Thus, we split the phyloseq object into multiple phyloseq objects corresponding to each block, and store the phyloseq objects as a list of phyloseq objects, `psByBlock`. 

We select negative control samples from each block and store as a list of phyloseq objects, `psNCbyBlock`. 

We select all taxa that have a prevalence of zero (i.e., have zero reads) in all negative control samples for each block and store as a list of phyloseq objects, `psallzeroInNC`.

We select all specimen samples from each block and store as a list of phyloseq objects, `psPlByBlock`.

```{r list_of_phyloseq}
psBlockResult = psBlockResults(ps, 
                               sampleTypeVar = "SampleType",
                               caselevels = c("Standard"),
                               controllevel = c("Negative"),
                               sampleName = "sampleID", 
                               blockVar = "block")

psByBlock = psBlockResult[[1]]
psNCbyBlock = psBlockResult[[2]]
psallzeroInNC = psBlockResult[[3]]
psPlByBlock = psBlockResult[[4]]
```


##  Estimate the distribution parameters for the instensity of contamination in negative control samples

Estimate the gamma distribution parameters for the intensity of contaminants using the negative control samples for each block. 
<!-- Choosing `stringent == TRUE` specifies BARBI to not using the scaling property for the species with the mean intensity of contamination less than one. This is one of two parameters that allows for more stringent subtraction of contaminants, especially for those at low abundance in negative control samples. -->

```{r estimate_Cont_Intensity_ncontrols}
alphaBetaNegControl = alphaBetaNegControl(psNCbyBlock = psNCbyBlock)
```



##  Estimate the distribution parameters for the intensity of contamination in each specimen sample

For each specimen sample, estimate the gamma distribution parameters for the intensity of contamination using the scaling property of the gamma distribution.

```{r estimate_Cont_Intensity_specimen}
num_blks = length(alphaBetaNegControl)
blks = seq(1, num_blks) %>% as.list

gammaPrior_all_blks = lapply(blks, function(x){
    gammaPrior = alphaBetaContInPlasma(psPlByBlock = psPlByBlock, 
                                       psallzeroInNC = psallzeroInNC, 
                                       blk = x,
                                       alphaBetaNegControl=alphaBetaNegControl)
        return(gammaPrior)
})
```


##  Sample from the posterior for the true intensities

For all specimen samples and for all taxa, sample from the posterior for the true intensities using the Metropolis-Hasting MCMC. 

We need to specifify the number of iterations in the MCMC using the option `itera`. 

Save the gamma prior for the intensity of contamination and the posterior samples.

The  suggeseted itera is 10,000. 

```{r sampling_post_true_int}
t1 = proc.time()

post_all_blocks = lapply(blks,function(x){
    post_int_all_taxa = samplingPosterior(psPlByBlock = psPlByBlock,
                                          blk = x,
                                          gammaPrior_Cont = gammaPrior_all_blks[[x]],
                                          itera = 100)
    return(post_int_all_taxa)
})

proc.time()-t1


gammaPrior_posTrueSing_all_blocks = list(gammaPrior_all_blks,post_all_blocks)
```

We can save the results.
```{r eval=FALSE}
saveRDS(gammaPrior_posTrueSing_all_blocks, file= "./gammaPrior_posTrueSing_all_blocks.rds")
```


# Display the results

##  Make summaires from the BARBI results.

Choose the number of MCMC to be removed using the option `burnIn`.  It must be less than `itera`.

Choose the coverage probability to construct the highest posterior density (HPD) interval$\left(L_{ij}^{(r)}, U_{ij}^{(r)}\right)$ (for each taxon $i$ in a specimen $j$) using the option `cov.pro` for true intensities.

Compute the highest density interval (HDI) for the contaminant internsities $\left(L_{ij}^{(c)}, U_{ij}^{(c)}\right)$ for each taxon $i$ in a specimen $j$.

For a contaminant taxon, the lower limit $L_{ij}^{(r)}$ will be smaller than the upper limit $U_{ij}^{(c)}$.

The suggested burnIn is 5000 for itera = 10,000.
```{r make_tables}
itera = 100
burnIn = 10
cov.pro = .95
mak_tab = TRUE

# psByBlock = readRDS("./psByBlock.rds")

# gammaPrior_posTrueSing_all_blocks = readRDS("./gammaPrior_posTrueSing_all_blocks.rds")

gammaPrior_all_blks = gammaPrior_posTrueSing_all_blocks[[1]]
post_all_blocks = gammaPrior_posTrueSing_all_blocks[[2]]

all_real_taxa_lt = list()

for(blk in 1:num_blks){

    taxa_post_all_sam = post_all_blocks[[blk]]
    gammPrior = gammaPrior_all_blks[[blk]]

    total_summary_table = NULL

    all_real_taxa = character()

    for(sam in 1:nsamples(psPlByBlock[[blk]])){

        taxa_post = taxa_post_all_sam[[sam]]
        acceptance = list()
        # exp_post_s = list()
        lower.t = list()
        upper.t = list()
        lower.c = list()
        upper.c = list()
        all.zero.nc = list()

        for(taxa in 1:length(taxa_post)){
            burnIn  = burnIn
            acceptance[[taxa]]  =  1-mean(duplicated(taxa_post[[taxa]][-(1:burnIn),]))

            # exp_post_s[[taxa]] = mean(taxa_post[[taxa]][-(1:burnIn),])

            hdi.v = hdi(taxa_post[[taxa]][-(1:burnIn),],
                        credMass = cov.pro)
            lower.t[[taxa]] = round(hdi.v[1], digits = 0)
            upper.t[[taxa]] = round(hdi.v[2], digits = 0)
            bb = rgamma((itera-burnIn+1), 
                        shape= gammPrior[[sam]][[1]][taxa],
                        rate = gammPrior[[sam]][[2]][taxa])
            
            # exp_bb = gammPrior[[sam]][[1]][taxa]/gammPrior[[sam]][[2]][taxa]

            hdi.b = hdi(bb, credMass = cov.pro)
            lower.c[[taxa]] = round(hdi.b[1], digits = 0)
            upper.c[[taxa]] = round(hdi.b[2], digits = 0)
            
            all.zero.nc[[taxa]] =  gammPrior[[sam]][[5]][taxa]
                
        }


        df = data.frame(Species = taxa_names(psPlByBlock[[blk]]),
                        xj = as.numeric(gammPrior[[sam]][[3]]),
                        l.t = unlist(lower.t),
                        u.t = unlist(upper.t),
                        l.c = unlist(lower.c),
                        u.c = unlist(upper.c),
                        all.zero.nc = unlist(all.zero.nc))
        
        # List all true taxa
        df = arrange(filter(df,(l.t > u.c) & (l.t > 0)),
                     desc(xj))

        # If there is no true taxa
        if(dim(df)[1]==0){
            df = data.frame(Species="Negative",
                             xj="Negative",
                             l.t="Negative",
                             u.t="Negative",
                             l.c ="Negative",
                             u.c="Negative",
                             all.zero.nc = "Negative")
        }

        # collect all true taxa in the specimen
        all_real_taxa = c(all_real_taxa,
                          as.character(df$Species))
        
        if(mak_tab){
          filname = paste("./",
                          sample_names(psPlByBlock[[blk]])[sam],
                          ".png",
                          sep="")

          png(filname, height = 600, width = 750)

          df.p = tableGrob(df)
          title = textGrob(sample_names(psPlByBlock[[blk]])[sam], 
                           gp = gpar(fontsize = 12))

          padding = unit(0.5,"line")

          df.p = gtable_add_rows(df.p, 
                                 heights = grobHeight(title) + padding, 
                                 pos = 0)

          df.p = gtable_add_grob(df.p, 
                                 list(title),
                                 t = 1, 
                                 l = 1, 
                                 r = ncol(df.p))

          grid.newpage()
          grid.draw(df.p)
          dev.off()
        }


        all_real_taxa = unique(all_real_taxa)
    }

    all_real_taxa_lt[[blk]] = all_real_taxa
}
```

## Construct a phyloseq object with the true taxa
```{r make_phyloseq}
all_real_taxa_lt = unlist(all_real_taxa_lt)
all_real_taxa_lt = all_real_taxa_lt[which(!all_real_taxa_lt == "Negative")]
ps_decon = prune_taxa(all_real_taxa_lt, ps)
ps_decon
```

# Session Info 

```{r session_info}
sessionInfo()
```
